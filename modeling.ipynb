{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da146bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/15/d1b649fc7685d11b806b4546a5438191fb2ad761de70da95ff676189dcec/scikit_learn-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1MB)\n",
      "\u001b[K     |████████████████████████████████| 11.1MB 7.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/f0/fb07a9548e48b687b8bf2fa81d71aba9cfc548d365046ca1c791e24db99d/scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5MB)\n",
      "\u001b[K     |████████████████████████████████| 34.5MB 89.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl\n",
      "Collecting numpy>=1.17.3\n",
      "  Using cached https://files.pythonhosted.org/packages/98/5d/5738903efe0ecb73e51eb44feafba32bdba2081263d40c5043568ff60faf/numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Collecting joblib>=1.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl (302kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 101.8MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy, threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 numpy-1.24.4 scikit-learn-1.3.0 scipy-1.10.1 threadpoolctl-3.2.0\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy-1.24.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\n",
      "\u001b[33mWARNING: Target directory /tmp/pip_packages/bin already exists. Specify --upgrade to force replacement.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#! pip install \"snowflake-connector-python[pandas]\"\n",
    "# ! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ba1d266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/snowflake/connector/options.py:103: UserWarning: You have an incompatible version of 'pyarrow' installed (10.0.1), please install a version that adheres to: 'pyarrow<8.1.0,>=8.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark import Session\n",
    "import configparser\n",
    "def get_session():\n",
    "    parser = configparser.ConfigParser()\n",
    "    # Add the credential file name here\n",
    "    parser.read('config.ini')\n",
    "\n",
    "    connection_params = dict(user=parser['Credentials']['user'], \n",
    "                         password=parser['Credentials']['password'], \n",
    "                         account=parser['Credentials']['account'], \n",
    "                         warehouse=parser['Credentials']['warehouse'], \n",
    "                         database=parser['Credentials']['database'],\n",
    "                         schema=parser['Credentials']['schema'], \n",
    "                         role=parser['Credentials']['role'])\n",
    "\n",
    "    session = Session.builder.configs(connection_params).create()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ade4317",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78007a5",
   "metadata": {},
   "source": [
    "#### Load the prepared data from snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c311e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = session.sql(\"SELECT * from {table}\".format(table=\"predictive_maintenance_final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d0d0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FAILURE',\n",
       " 'METRIC5',\n",
       " 'METRIC6',\n",
       " 'DAY',\n",
       " 'DAY_WEEK',\n",
       " 'SECTOR',\n",
       " 'OP_PERIOD',\n",
       " 'DEV_RECONNECTED',\n",
       " 'MNW1',\n",
       " 'DIF_M6',\n",
       " 'DIF_M5',\n",
       " 'LOG_M2',\n",
       " 'LOG_M3',\n",
       " 'LOG_M4',\n",
       " 'LOG_M7',\n",
       " 'LOG_M9']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c1fe59",
   "metadata": {},
   "source": [
    "Prepare dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160db9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87ba7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer():\n",
    "    #add all imports\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.metrics import recall_score, f1_score, roc_auc_score, confusion_matrix,classification_report\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    df = session.sql(\"SELECT * from {table}\".format(table=\"predictive_maintenance_final\"))\n",
    "    \n",
    "    # prepare data for training\n",
    "    X = df_final.drop(['FAILURE'], axis = 1)\n",
    "    y = df_final['FAILURE']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,y,random_state = 0, test_size=0.25, shuffle = True)\n",
    "    X_train.reset_index(inplace = True, drop = True)\n",
    "    Y_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    X_test.reset_index(inplace = True, drop = True)\n",
    "    Y_test.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, random_state = 0, test_size=0.25)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('OHE', OneHotEncoder(handle_unknown = 'ignore',sparse=False)),\n",
    "#         ('SCALER', StandardScaler()),\n",
    "        ('SGD', SGDClassifier(random_state=0))\n",
    "     ])\n",
    "    \n",
    "    pipeline.fit(x_train,y_train)\n",
    "    y_pred = pipeline.predict(x_val) \n",
    "    cf_matrix = confusion_matrix(y_val, y_pred)\n",
    "    cls_report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    print(cls_report)\n",
    "    return pipeline, y_pred, cls_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c12c2763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     23323\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           1.00     23343\n",
      "   macro avg       0.50      0.50      0.50     23343\n",
      "weighted avg       1.00      1.00      1.00     23343\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/pip_packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/pip_packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cls_report = trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e77f44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7004d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import sproc\n",
    "\n",
    "@sproc(name=\"predictive_maintenance\", is_permanent=True, stage_location=\"@TRAINERS\", replace=True, packages=[\"snowflake-snowpark-python\",\"scikit-learn\"])\n",
    "def train_model(session: Session, features_table: str) -> dict:\n",
    "    import os\n",
    "    import time\n",
    "    from joblib import dump\n",
    "    start_time = time.time()\n",
    "    df_final = session.sql(\"SELECT * from {table}\".format(table=\"predictive_maintenance_final\")).to_pandas()[:20000]\n",
    "    \n",
    "    def trainer():\n",
    "        #add all imports\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        from sklearn.metrics import recall_score, f1_score, roc_auc_score, confusion_matrix,classification_report\n",
    "        from sklearn.linear_model import SGDClassifier\n",
    "        from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    # prepare data for training\n",
    "        X = df_final.drop(['FAILURE'], axis = 1)\n",
    "        y = df_final['FAILURE']\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X,y,random_state = 0, test_size=0.25, shuffle = True)\n",
    "        X_train.reset_index(inplace = True, drop = True)\n",
    "        Y_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "        X_test.reset_index(inplace = True, drop = True)\n",
    "        Y_test.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "        x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, random_state = 0, test_size=0.25)\n",
    "    \n",
    "        pipeline = Pipeline([\n",
    "            ('OHE', OneHotEncoder(handle_unknown = 'ignore',sparse=False)),\n",
    "#         ('SCALER', StandardScaler()),\n",
    "            ('SGD', SGDClassifier(random_state=0))\n",
    "         ])\n",
    "    \n",
    "        pipeline.fit(x_train,y_train)\n",
    "        y_pred = pipeline.predict(x_val) \n",
    "        cf_matrix = confusion_matrix(y_val, y_pred)\n",
    "        cls_report = classification_report(y_val, y_pred, output_dict=True)\n",
    "        print(cls_report)\n",
    "        return pipeline, cls_report\n",
    "    pipeline, cls_report = trainer()\n",
    "    seconds = time.time() - start_time\n",
    "    time_taken = str(time.strftime(\"%H:%M:%S\",time.gmtime(seconds)))\n",
    "    from datetime import datetime\n",
    "    currentDateAndTime = datetime.now()\n",
    "    model_filename = \"Predictive_Maintenance_model_\"+currentDateAndTime.strftime('%Y%m%d_%H%M%S') + '.joblib'\n",
    "    \n",
    "    model_file_path = os.path.join('/tmp',model_filename)\n",
    "    dump(pipeline, model_file_path)\n",
    "    \n",
    "    session.file.put(model_file_path, \"@MODELS\" ,overwrite=True)\n",
    "    \n",
    "    return {\"model_name\":model_filename, \"classification_report\":cls_report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "674db2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = train_model(session,\"predictive_maintenance_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63b7e299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"classification_report\": {\\n    \"0\": {\\n      \"f1-score\": 1,\\n      \"precision\": 1,\\n      \"recall\": 1,\\n      \"support\": 3750\\n    },\\n    \"accuracy\": 1,\\n    \"macro avg\": {\\n      \"f1-score\": 1,\\n      \"precision\": 1,\\n      \"recall\": 1,\\n      \"support\": 3750\\n    },\\n    \"weighted avg\": {\\n      \"f1-score\": 1,\\n      \"precision\": 1,\\n      \"recall\": 1,\\n      \"support\": 3750\\n    }\\n  },\\n  \"model_name\": \"Predictive_Maintenance_model_20230919_194031.joblib\"\\n}'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.call(\"predictive_maintenance\",'predictive_maintenance_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4848995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
