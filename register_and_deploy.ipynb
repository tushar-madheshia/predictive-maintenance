{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95601cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "import configparser\n",
    "def get_session():\n",
    "    parser = configparser.ConfigParser()\n",
    "    # Add the credential file name here\n",
    "    parser.read('config.ini')\n",
    "\n",
    "    connection_params = dict(user=parser['Credentials']['user'], \n",
    "                         password=parser['Credentials']['password'], \n",
    "                         account=parser['Credentials']['account'], \n",
    "                         warehouse=parser['Credentials']['warehouse'], \n",
    "                         database=parser['Credentials']['database'],\n",
    "                         schema=parser['Credentials']['schema'], \n",
    "                         role=parser['Credentials']['role'])\n",
    "\n",
    "    session = Session.builder.configs(connection_params).create()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9188f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05fb7b3",
   "metadata": {},
   "source": [
    "### Deploy the model from stage location as a UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ef8d0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package joblib in the local environment is 1.3.2, which does not fit the criteria for the requirement joblib. Your UDF might not work when the package version is different between the server and your local environment\n"
     ]
    }
   ],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()\n",
    "from snowflake.snowpark.functions import udf,call_udf\n",
    "\n",
    "# Add trained model as dependency\n",
    "session.add_import(\"@models/Predictive_Maintenance_model_20230919_194031.joblib.gz\")\n",
    "import pandas\n",
    "@udf(name='predict', session=session,is_permanent=True,replace=True,stage_location=\"@SCORE\",packages=[\"snowflake-snowpark-python\",\"pandas\", \"joblib\",\"scikit-learn\"])\n",
    "def score(payload: list) -> str:\n",
    "    import sys\n",
    "    import pandas as pd\n",
    "    from joblib import load\n",
    "\n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "\n",
    "    pipeline_file = import_dir + 'Predictive_Maintenance_model_20230919_194031.joblib.gz'\n",
    "    pipeline = load(pipeline_file)\n",
    "\n",
    "    prediction = pipeline.predict(df)[0]\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a693f",
   "metadata": {},
   "source": [
    "#### Sample Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a1d13d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp =[6,407438,1,3,'S1F0',1,0,26953834,0,0,2.079441541679836,0.0,3.9702919135521215,0.0,2.079441541679836]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebcc6e1",
   "metadata": {},
   "source": [
    "Consuming the model one request at a time. For batch inferenece, deploy the model as vectorized UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7bb690bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = session.sql(\"select PREDICT(\"+str(inp)+\")\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6649c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PREDICT([6, 407438, 1, 3, 'S1F0', 1, 0, 26953834, 0, 0, 2.079441541679836, 0.0, 3.9702919135521215, 0.0, 2.079441541679836])='0')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92c9bc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9991432120978452, 'recall': 1.0, 'f1-score': 0.9995714224488921, 'support': 23323.0}, '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 20.0}, 'accuracy': 0.9991432120978452, 'macro avg': {'precision': 0.4995716060489226, 'recall': 0.5, 'f1-score': 0.49978571122444604, 'support': 23343.0}, 'weighted avg': {'precision': 0.9982871582811996, 'recall': 0.9991432120978452, 'f1-score': 0.9987150017467982, 'support': 23343.0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "    #add all imports\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.metrics import recall_score, f1_score, roc_auc_score, confusion_matrix,classification_report\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    df_final = session.sql(\"SELECT * from {table}\".format(table=\"predictive_maintenance_final\")).to_pandas()\n",
    "    \n",
    "    # prepare data for training\n",
    "    X = df_final.drop(['FAILURE'], axis = 1)\n",
    "    y = df_final['FAILURE']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,y,random_state = 0, test_size=0.25, shuffle = True)\n",
    "    X_train.reset_index(inplace = True, drop = True)\n",
    "    Y_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    X_test.reset_index(inplace = True, drop = True)\n",
    "    Y_test.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, random_state = 0, test_size=0.25)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('OHE', OneHotEncoder(handle_unknown = 'ignore',sparse=False)),\n",
    "#         ('SCALER', StandardScaler()),\n",
    "        ('SGD', SGDClassifier(random_state=0))\n",
    "     ])\n",
    "    \n",
    "    pipeline.fit(x_train,y_train)\n",
    "    y_pred = pipeline.predict(x_val) \n",
    "    cf_matrix = confusion_matrix(y_val, y_pred)\n",
    "    cls_report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f91aaa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pipeline, open(\"/data/pipeline.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bdc3e18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pipeline = pickle.load(open(\"/data/pipeline.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b183f0",
   "metadata": {},
   "source": [
    "Write the score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e79c66b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f999727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    payload = request.json[\"payload\"]\n",
    "    prediction = pipeline.predict([payload])[0]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c588ef3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but OneHotEncoder was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "req = requests.Request()\n",
    "req.json = {\"payload\":[6,407438,1,3,'S1F0',1,0,26953834,0,0,2.079441541679836,0.0,3.9702919135521215,0.0,2.079441541679836]}\n",
    "print(score(loaded_pipeline,req))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff36c141",
   "metadata": {},
   "source": [
    "### Register on refract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6d0e7f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## registering the model in refract.\n",
    "tmp = register_model(loaded_pipeline, \n",
    "               score, \n",
    "               name=\"Predictive_Maintenance\", \n",
    "               description=\"By analyzing data patterns and using machine learning algorithms, it predicts when maintenance is needed, allowing organizations to perform repairs or servicing precisely when required, minimizing downtime, reducing costs, and preventing unexpected equipment failures. This approach enhances operational efficiency and extends the lifespan of assets by addressing maintenance needs based on data-driven insights rather than fixed schedules.\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               y_true=y_val,\n",
    "               y_pred=y_pred, \n",
    "               features=x_train.columns,\n",
    "               labels=[0,1],\n",
    "               feature_names=X_train.columns.tolist(),\n",
    "               original_features=X_train.columns.tolist(),\n",
    "               feature_ids=X_train.columns,\n",
    "               kyd=True, kyd_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194f99cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
