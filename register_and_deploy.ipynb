{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95601cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "import configparser\n",
    "def get_session():\n",
    "    parser = configparser.ConfigParser()\n",
    "    # Add the credential file name here\n",
    "    parser.read('config.ini')\n",
    "\n",
    "    connection_params = dict(user=parser['Credentials']['user'], \n",
    "                         password=parser['Credentials']['password'], \n",
    "                         account=parser['Credentials']['account'], \n",
    "                         warehouse=parser['Credentials']['warehouse'], \n",
    "                         database=parser['Credentials']['database'],\n",
    "                         schema=parser['Credentials']['schema'], \n",
    "                         role=parser['Credentials']['role'])\n",
    "\n",
    "    session = Session.builder.configs(connection_params).create()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9188f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05fb7b3",
   "metadata": {},
   "source": [
    "### Deploy the model from stage location as a UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef8d0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package joblib in the local environment is 1.3.2, which does not fit the criteria for the requirement joblib. Your UDF might not work when the package version is different between the server and your local environment\n"
     ]
    }
   ],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()\n",
    "from snowflake.snowpark.functions import udf,call_udf\n",
    "\n",
    "# Add trained model as dependency\n",
    "session.add_import(\"@models/Predictive_Maintenance_model_20230919_194031.joblib.gz\")\n",
    "import pandas\n",
    "@udf(name='predict', session=session,is_permanent=True,replace=True,stage_location=\"@SCORE\",packages=[\"snowflake-snowpark-python\",\"pandas\", \"joblib\",\"scikit-learn\"])\n",
    "def score(payload: list) -> str:\n",
    "    import sys\n",
    "    import pandas as pd\n",
    "    from joblib import load\n",
    "\n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "\n",
    "    pipeline_file = import_dir + 'Predictive_Maintenance_model_20230919_194031.joblib.gz'\n",
    "    pipeline = load(pipeline_file)\n",
    "\n",
    "    prediction = pipeline.predict([payload])[0]\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94a693f",
   "metadata": {},
   "source": [
    "#### Sample Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1d13d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp =[6,407438,1,3,'S1F0',1,0,26953834,0,0,2.079441541679836,0.0,3.9702919135521215,0.0,2.079441541679836]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebcc6e1",
   "metadata": {},
   "source": [
    "Consuming the model one request at a time. For batch inferenece, deploy the model as vectorized UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb690bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = session.sql(\"select PREDICT(\"+str(inp)+\")\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6649c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(PREDICT([6, 407438, 1, 3, 'S1F0', 1, 0, 26953834, 0, 0, 2.079441541679836, 0.0, 3.9702919135521215, 0.0, 2.079441541679836])='0')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53d935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1875}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1875}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 1875}}\n"
     ]
    }
   ],
   "source": [
    "    #add all imports\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.metrics import recall_score, f1_score, roc_auc_score, confusion_matrix,classification_report\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    df_final = session.sql(\"SELECT * from {table}\".format(table=\"predictive_maintenance_final\")).to_pandas()[:10000]\n",
    "    \n",
    "    # prepare data for training\n",
    "    X = df_final.drop(['FAILURE'], axis = 1)\n",
    "    y = df_final['FAILURE']\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,y,random_state = 0, test_size=0.25, shuffle = True)\n",
    "    X_train.reset_index(inplace = True, drop = True)\n",
    "    Y_train.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    X_test.reset_index(inplace = True, drop = True)\n",
    "    Y_test.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, random_state = 0, test_size=0.25)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('OHE', OneHotEncoder(handle_unknown = 'ignore',sparse=False)),\n",
    "#         ('SCALER', StandardScaler()),\n",
    "        ('SGD', RandomForestClassifier(random_state=0))\n",
    "     ])\n",
    "    \n",
    "    pipeline.fit(x_train,y_train)\n",
    "    y_pred = pipeline.predict(x_val) \n",
    "    cf_matrix = confusion_matrix(y_val, y_pred)\n",
    "    cls_report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef806d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m----> 2\u001b[0m pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict_proba_True\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPREDICTION\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPREDICTION\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROBABILITIES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "pred = pipeline.predict(X_test)\n",
    "pred[\"probabilities\"] = pipeline.predict_proba(X_test)\n",
    "X_test[\"PREDICTION\"] = pred[\"PREDICTION\"]\n",
    "X_test[\"PROBABILITIES\"] = pred[\"probabilities\"]\n",
    "X_test[\"LABEL\"] = Y_test\n",
    "\n",
    "y_prob_r = np.array(X_test[\"PROBABILITIES\"])\n",
    "y_test_r = pred[\"CHURN\"]\n",
    "y_pred_r = pred[\"PREDICTION\"]\n",
    "X_test = X_test.drop([\"CHURN\", \"PREDICTION\", \"probabilities\"], axis=1)\n",
    "# y_train = train[\"CHURN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1eac5ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pipeline, open(\"/data/pipeline.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8046351",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loaded_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/pipeline.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "loaded_pipeline = pickle.load(open(\"/data/pipeline.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666769ea",
   "metadata": {},
   "source": [
    "Write the score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "209dd3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/pip_packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "from refractml import *\n",
    "from refractml.constants import MLModelFlavours\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc9ae5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@scoring_func\n",
    "def score(model, request):\n",
    "    payload = request.json[\"payload\"]\n",
    "    prediction = pipeline.predict([payload])[0]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26f98065",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m req \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mRequest()\n\u001b[1;32m      2\u001b[0m req\u001b[38;5;241m.\u001b[39mjson \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m407438\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS1F0\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m26953834\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2.079441541679836\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m3.9702919135521215\u001b[39m,\u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m2.079441541679836\u001b[39m]}\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(score(\u001b[43mloaded_pipeline\u001b[49m,req))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loaded_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "req = requests.Request()\n",
    "req.json = {\"payload\":[6,407438,1,3,'S1F0',1,0,26953834,0,0,2.079441541679836,0.0,3.9702919135521215,0.0,2.079441541679836]}\n",
    "print(score(loaded_pipeline,req))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd58f096",
   "metadata": {},
   "source": [
    "### Register on refract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "170c5b5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'register_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## registering the model in refract.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mregister_model\u001b[49m(loaded_pipeline, \n\u001b[1;32m      3\u001b[0m                score, \n\u001b[1;32m      4\u001b[0m                name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictive_Maintenance\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      5\u001b[0m                description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBy analyzing data patterns and using machine learning algorithms, it predicts when maintenance is needed, allowing organizations to perform repairs or servicing precisely when required, minimizing downtime, reducing costs, and preventing unexpected equipment failures. This approach enhances operational efficiency and extends the lifespan of assets by addressing maintenance needs based on data-driven insights rather than fixed schedules.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m                flavour\u001b[38;5;241m=\u001b[39mMLModelFlavours\u001b[38;5;241m.\u001b[39msklearn,\n\u001b[1;32m      7\u001b[0m                model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m                y_true\u001b[38;5;241m=\u001b[39my_val,\n\u001b[1;32m      9\u001b[0m                y_pred\u001b[38;5;241m=\u001b[39my_pred, \n\u001b[1;32m     10\u001b[0m                features\u001b[38;5;241m=\u001b[39mx_train\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[1;32m     11\u001b[0m                labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#                input_type=\"json\", \u001b[39;00m\n\u001b[1;32m     13\u001b[0m                explain_ai\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m                x_train\u001b[38;5;241m=\u001b[39mx_train, \n\u001b[1;32m     15\u001b[0m                x_test\u001b[38;5;241m=\u001b[39mx_val, \n\u001b[1;32m     16\u001b[0m                y_train\u001b[38;5;241m=\u001b[39my_train\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m     17\u001b[0m                y_test\u001b[38;5;241m=\u001b[39my_val\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m     18\u001b[0m                feature_names\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m     19\u001b[0m                original_features\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m     20\u001b[0m                feature_ids\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mcolumns,)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'register_model' is not defined"
     ]
    }
   ],
   "source": [
    "## registering the model in refract.\n",
    "register_model(loaded_pipeline, \n",
    "               score, \n",
    "               name=\"Predictive_Maintenance\", \n",
    "               description=\"By analyzing data patterns and using machine learning algorithms, it predicts when maintenance is needed, allowing organizations to perform repairs or servicing precisely when required, minimizing downtime, reducing costs, and preventing unexpected equipment failures. This approach enhances operational efficiency and extends the lifespan of assets by addressing maintenance needs based on data-driven insights rather than fixed schedules.\",\n",
    "               flavour=MLModelFlavours.sklearn,\n",
    "               model_type=\"classification\",\n",
    "               y_true=y_val,\n",
    "               y_pred=y_pred, \n",
    "               features=x_train.columns,\n",
    "               labels=[0,1],\n",
    "#                input_type=\"json\", \n",
    "               explain_ai=True,\n",
    "               x_train=x_train, \n",
    "               x_test=x_val, \n",
    "               y_train=y_train.tolist(),\n",
    "               y_test=y_val.tolist(),\n",
    "               feature_names=X_train.columns.tolist(),\n",
    "               original_features=X_train.columns.tolist(),\n",
    "               feature_ids=X_train.columns,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46950011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
